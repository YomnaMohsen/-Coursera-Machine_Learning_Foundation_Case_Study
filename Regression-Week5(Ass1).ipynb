{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using Turi Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up Turi Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "                'bathrooms',\n",
    "                'sqft_living', 'sqft_living_sqrt',\n",
    "                'sqft_lot', 'sqft_lot_sqrt',\n",
    "                'floors', 'floors_square',\n",
    "                'waterfront', 'view', 'condition', 'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in Turi Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-218136.2140351407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     0.        ,     0.        ,   134.43931396,\n",
       "           0.        ,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,     0.        , 24750.00458561,     0.        ,\n",
       "       61749.10309071,     0.        ,     0.        ,    -0.        ,\n",
       "           0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l1_penalty = 5e2\n",
    "model_all=Lasso(alpha=l1_penalty,normalize=True)\n",
    "model_all.fit(sales[all_features],sales['price'])\n",
    "print(model_all.intercept_)\n",
    "model_all.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('kc_house_valid_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398213327300134.5 10.0\n",
      "399041900253348.7 31.622776601683793\n",
      "429791604072558.4 100.0\n",
      "463739831045119.5 316.22776601683796\n",
      "645898733633803.0 1000.0\n",
      "1222506859427156.8 3162.2776601683795\n",
      "1222506859427156.8 10000.0\n",
      "1222506859427156.8 31622.776601683792\n",
      "1222506859427156.8 100000.0\n",
      "1222506859427156.8 316227.7660168379\n",
      "1222506859427156.8 1000000.0\n",
      "1222506859427156.8 3162277.6601683795\n",
      "1222506859427156.8 10000000.0\n",
      "(10.0, 398213327300134.5)\n"
     ]
    }
   ],
   "source": [
    "penalty_list=np.logspace(1, 7, num=13)\n",
    "list1={}\n",
    "for l1_penalty in (penalty_list):\n",
    "    model_all=Lasso(alpha=l1_penalty,normalize=True)\n",
    "    model_all.fit(training[all_features],training['price'])\n",
    "    predict_v= model_all.predict(validation[all_features])\n",
    "    rss_v=validation['price']-predict_v\n",
    "    rss_sq=rss_v*rss_v\n",
    "    rss=sum(rss_sq)\n",
    "    list1[l1_penalty]=rss\n",
    "    print(rss,l1_penalty)\n",
    "   # list1.append(rss)\n",
    "print(min(list1.items(),key=lambda x: x[1])) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION. *** What was the best value for the `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty = 10.0\n",
    "model_all=Lasso(alpha=l1_penalty,normalize=True)\n",
    "model_all.fit(training[all_features],training['price'])\n",
    "\n",
    "np.count_nonzero(model_all.coef_) + np.count_nonzero(model_all.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model.coefficients['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero(list):\n",
    "    count=0\n",
    "    for i in range(17):\n",
    "        if(list[i]>0.0):\n",
    "            #print(list[i])\n",
    "            count+=1\n",
    "        if(list[i]<0.0):\n",
    "            count+=1 \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty 10.0 coef 14\n",
      "penalty 14.38449888287663 coef 14\n",
      "penalty 20.6913808111479 coef 14\n",
      "penalty 29.76351441631318 coef 14\n",
      "penalty 42.81332398719393 coef 12\n",
      "penalty 61.58482110660264 coef 11\n",
      "penalty 88.58667904100822 coef 10\n",
      "penalty 127.42749857031335 coef 9\n",
      "penalty 183.29807108324357 coef 6\n",
      "penalty 263.6650898730358 coef 5\n",
      "penalty 379.26901907322497 coef 5\n",
      "penalty 545.5594781168514 coef 5\n",
      "penalty 784.7599703514607 coef 4\n",
      "penalty 1128.8378916846884 coef 2\n",
      "penalty 1623.776739188721 coef 2\n",
      "penalty 2335.7214690901214 coef 1\n",
      "penalty 3359.818286283781 coef 0\n",
      "penalty 4832.930238571752 coef 0\n",
      "penalty 6951.927961775606 coef 0\n",
      "penalty 10000.0 coef 0\n"
     ]
    }
   ],
   "source": [
    "coef_dict={}\n",
    "for l1_penalty in np.logspace(1, 4, num=20):\n",
    "    model_all=Lasso(alpha=l1_penalty,normalize=True)\n",
    "    model_all.fit(training[all_features],training['price'])\n",
    "   # print(model_all.coef_)\n",
    "   # count_w=count_zero(model_all.coef_)\n",
    "    coef_dict[l1_penalty]=np.count_nonzero(model_all.coef_)\n",
    "    print(\"penalty\",l1_penalty,\"coef\",np.count_nonzero(model_all.coef_))\n",
    "#print(coef_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzeros` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzeros` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty_min = 127\n",
    "l1_penalty_max = 545"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION.*** What values did you find for `l1_penalty_min` and `l1_penalty_max`, respectively? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435280594306308.6 127.0 9 [-2.89806863e+03 -0.00000000e+00  1.63890625e+04  1.64984227e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -4.95090306e+01  0.00000000e+00\n",
      "  4.13090230e+02  5.29180657e+05  4.24235012e+04  0.00000000e+00\n",
      "  1.18489264e+05  0.00000000e+00  0.00000000e+00 -2.83144140e+03\n",
      "  0.00000000e+00]\n",
      "439167100557623.4 149.0 7 [-0.00000000e+00 -0.00000000e+00  1.19216405e+04  1.63205389e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -8.47647396e+00  0.00000000e+00\n",
      "  0.00000000e+00  5.12243330e+05  4.21104104e+04  0.00000000e+00\n",
      "  1.16972320e+05  0.00000000e+00  0.00000000e+00 -2.66288375e+03\n",
      "  0.00000000e+00]\n",
      "441629330447945.4 171.0 6 [-0.00000000e+00 -0.00000000e+00  7.45089377e+03  1.64385451e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  4.94582208e+05  4.17082763e+04  0.00000000e+00\n",
      "  1.14693948e+05  0.00000000e+00  0.00000000e+00 -2.50355122e+03\n",
      "  0.00000000e+00]\n",
      "444380248202994.25 193.0 6 [-0.00000000e+00 -0.00000000e+00  2.78520905e+03  1.65868625e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  4.77046639e+05  4.13361027e+04  0.00000000e+00\n",
      "  1.12390131e+05  0.00000000e+00  0.00000000e+00 -2.34300669e+03\n",
      "  0.00000000e+00]\n",
      "447298074348216.7 215.0 5 [-0.00000000e+00 -0.00000000e+00  0.00000000e+00  1.66385303e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  4.59491232e+05  4.09562426e+04  0.00000000e+00\n",
      "  1.10005601e+05  0.00000000e+00  0.00000000e+00 -2.19599013e+03\n",
      "  0.00000000e+00]\n",
      "450172070087694.1 237.0 5 [-0.00000000e+00 -0.00000000e+00  0.00000000e+00  1.65441612e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  4.41906071e+05  4.05663856e+04  0.00000000e+00\n",
      "  1.07513248e+05  0.00000000e+00  0.00000000e+00 -2.06892494e+03\n",
      "  0.00000000e+00]\n",
      "453435012656395.0 259.0 5 [-0.00000000e+00 -0.00000000e+00  0.00000000e+00  1.64507842e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  4.24317289e+05  4.01776229e+04  0.00000000e+00\n",
      "  1.05014482e+05  0.00000000e+00  0.00000000e+00 -1.94184379e+03\n",
      "  0.00000000e+00]\n",
      "457085565406580.8 281.0 5 [-0.00000000e+00  0.00000000e+00  0.00000000e+00  1.63564063e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  4.06732160e+05  3.97877563e+04  0.00000000e+00\n",
      "  1.02522185e+05  0.00000000e+00  0.00000000e+00 -1.81477873e+03\n",
      "  0.00000000e+00]\n",
      "461124463331584.5 303.0 5 [-0.00000000e+00  0.00000000e+00  0.00000000e+00  1.62620827e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.89146833e+05  3.93979496e+04  0.00000000e+00\n",
      "  1.00029537e+05  0.00000000e+00  0.00000000e+00 -1.68771281e+03\n",
      "  0.00000000e+00]\n",
      "465551679349479.94 325.0 5 [-0.00000000e+00  0.00000000e+00  0.00000000e+00  1.61677768e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.71561441e+05  3.90081625e+04  0.00000000e+00\n",
      "  9.75367742e+04  0.00000000e+00  0.00000000e+00 -1.56064659e+03\n",
      "  0.00000000e+00]\n",
      "470367206934847.8 347.0 5 [-0.00000000e+00  0.00000000e+00  0.00000000e+00  1.60734811e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.53976012e+05  3.86183866e+04  0.00000000e+00\n",
      "  9.50439458e+04  0.00000000e+00  0.00000000e+00 -1.43358022e+03\n",
      "  0.00000000e+00]\n",
      "475571041141472.7 369.0 5 [-0.00000000e+00  0.00000000e+00  0.00000000e+00  1.59791854e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.36390582e+05  3.82286107e+04  0.00000000e+00\n",
      "  9.25511174e+04  0.00000000e+00  0.00000000e+00 -1.30651384e+03\n",
      "  0.00000000e+00]\n",
      "481163181969356.4 391.0 5 [-0.00000000e+00  0.00000000e+00  0.00000000e+00  1.58848897e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.18805153e+05  3.78388347e+04  0.00000000e+00\n",
      "  9.00582890e+04  0.00000000e+00  0.00000000e+00 -1.17944747e+03\n",
      "  0.00000000e+00]\n",
      "487143627978303.94 413.0 5 [-0.00000000e+00  0.00000000e+00  0.00000000e+00  1.57905821e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.01219767e+05  3.74490457e+04  0.00000000e+00\n",
      "  8.75655372e+04  0.00000000e+00  0.00000000e+00 -1.05238128e+03\n",
      "  0.00000000e+00]\n",
      "493512382308250.0 435.0 5 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.56962738e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  2.83634385e+05  3.70592558e+04  0.00000000e+00\n",
      "  8.50727905e+04  0.00000000e+00  0.00000000e+00 -9.25315108e+02\n",
      "  0.00000000e+00]\n",
      "500269445115061.5 457.0 5 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.56019654e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  2.66049002e+05  3.66694660e+04  0.00000000e+00\n",
      "  8.25800438e+04  0.00000000e+00  0.00000000e+00 -7.98248935e+02\n",
      "  0.00000000e+00]\n",
      "507414816398734.25 479.0 5 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.55076571e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  2.48463619e+05  3.62796761e+04  0.00000000e+00\n",
      "  8.00872972e+04  0.00000000e+00  0.00000000e+00 -6.71182763e+02\n",
      "  0.00000000e+00]\n",
      "514948496159270.6 501.0 5 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.54133487e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  2.30878236e+05  3.58898862e+04  0.00000000e+00\n",
      "  7.75945505e+04  0.00000000e+00  0.00000000e+00 -5.44116590e+02\n",
      "  0.00000000e+00]\n",
      "522870484396671.44 523.0 5 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.53190404e+02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  2.13292853e+05  3.55000963e+04  0.00000000e+00\n",
      "  7.51018038e+04  0.00000000e+00  0.00000000e+00 -4.17050417e+02\n",
      "  0.00000000e+00]\n",
      "531180781110934.5 545.0 5 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.52247320e+02\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.95707470e+05  3.51103064e+04  0.00000000e+00\n",
      "  7.26090571e+04  0.00000000e+00  0.00000000e+00 -2.89984245e+02\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\n",
    "    model_all=Lasso(alpha=l1_penalty,normalize=True)\n",
    "    model_all.fit(training[all_features],training['price'])\n",
    "    predict_v= model_all.predict(validation[all_features])\n",
    "    rss_v=validation['price']-predict_v\n",
    "    rss_sq=rss_v*rss_v\n",
    "    rss=sum(rss_sq)\n",
    "    print(rss,l1_penalty,np.count_nonzero(model_all.coef_),model_all.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4514867.826623703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00, -0.00000000e+00,  1.19216405e+04,  1.63205389e+02,\n",
       "        0.00000000e+00, -0.00000000e+00, -8.47647396e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  5.12243330e+05,  4.21104104e+04,  0.00000000e+00,\n",
       "        1.16972320e+05,  0.00000000e+00,  0.00000000e+00, -2.66288375e+03,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l1_penalty = 149\n",
    "model_all=Lasso(alpha=l1_penalty,normalize=True)\n",
    "model_all.fit(training[all_features],training['price'])\n",
    "print(model_all.intercept_)\n",
    "model_all.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
